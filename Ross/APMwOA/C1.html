<!DOCTYPE html><html><head><meta charset="UTF-8"><title>C1</title><style>/* 
Name: GeekPark article style for Mou app
Author: hzlzh(hzlzh.dev@gmail.com)
URL: https://github.com/GeekPark/Doc/blob/master/GeekPark/GeekPark-Style-for-Mou.css
*/
body{ font-family:"Microsoft Yahei","Helvetica Neue","Luxi Sans","DejaVu Sans",Tahoma,"Hiragino Sans GB",STHeiti; font-size:14px; line-height:1.6; color:#666666; padding-top:10px; padding-bottom:10px; background-color:white; padding:30px; }
body > *:first-child{ margin-top:0 !important; }
body > *:last-child{ margin-bottom:0 !important; }
a{ color:#109EFF; text-decoration:none; }
a:hover{ border-bottom:1px dotted #109EFF; }
a:visited, a:active{ color:#109EFF; }
a.absent{ color:#cc0000; }
a.anchor{ display:block; padding-left:30px; margin-left:-30px; cursor:pointer; position:absolute; top:0; left:0; bottom:0; }
p a{ margin:0 2px; }
h1, h2, h3, h4, h5, h6{ color:#333333; margin:20px 0 10px; padding:0; font-weight:bold; -webkit-font-smoothing:antialiased; cursor:text; position:relative; }
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor{ background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center; text-decoration:none; }
h1 tt, h1 code{ font-size:inherit; }
h2 tt, h2 code{ font-size:inherit; }
h3 tt, h3 code{ font-size:inherit; }
h4 tt, h4 code{ font-size:inherit; }
h5 tt, h5 code{ font-size:inherit; }
h6 tt, h6 code{ font-size:inherit; }
h1{ font-size:18px; font-weight:bold; line-height:22px; margin-bottom:5px; color:#333; }
h2{ font-size:16px; font-weight:bolder; line-height:18px; margin:20px 0; }
h3{ font-size:14px; }
h4{ color:#666; font-size:14px; font-weight:bolder; line-height:18px; margin:20px 0; }
h5{ font-size:14px; }
h6{ color:#777777; font-size:14px; }
p, blockquote, ul, ol, dl, li, table, pre{ margin:15px 0; line-height:150%; }
hr{ background:transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0; border:0 none; color:#cccccc; height:4px; padding:0; }
body > h2:first-child{ margin-top:0; padding-top:0; }
body > h1:first-child{ margin-top:0; padding-top:0; }
body > h1:first-child + h2{ margin-top:0; padding-top:0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child{ margin-top:0; padding-top:0; }
a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6{ margin-top:0; padding-top:0; }
h1 p, h2 p, h3 p, h4 p, h5 p, h6 p{ margin-top:0; }
li p.first{ display:inline-block; }
li{ font-size:14px; line-height:150%; margin-bottom:5px; margin-top:0; }
ul, ol{ padding-left:30px; }
ul :first-child, ol :first-child{ margin-top:0; }
dl{ padding:0; }
dl dt{ font-size:14px; font-weight:bold; font-style:italic; padding:0; margin:15px 0 5px; }
dl dt:first-child{ padding:0; }
dl dt > :first-child{ margin-top:0; }
dl dt > :last-child{ margin-bottom:0; }
dl dd{ margin:0 0 15px; padding:0 15px; }
dl dd > :first-child{ margin-top:0; }
dl dd > :last-child{ margin-bottom:0; }
blockquote{ background:url("data:image/png;base64,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") no-repeat scroll left 11px transparent; color:#999999; margin-left:28px; min-height:30px; padding:17px 40px 0; }
blockquote p{ color:#999999 !important; margin-bottom:25px !important; }
blockquote > :first-child{ margin-top:0; }
blockquote > :last-child{ margin-bottom:0; }
table{ padding:0; border-collapse:collapse; }
table tr{ border-top:1px solid #cccccc; background-color:white; margin:0; padding:0; }
table tr:nth-child(2n){ background-color:#f8f8f8; }
table tr th{ font-weight:bold; border:1px solid #cccccc; text-align:left; margin:0; padding:6px 13px; }
table tr td{ border:1px solid #cccccc; text-align:left; margin:0; padding:6px 13px; }
table tr th :first-child, table tr td :first-child{ margin-top:0; }
table tr th :last-child, table tr td :last-child{ margin-bottom:0; }
img{ border:1px solid #E1E1E1; margin:0 auto 10px; display:block; max-width:512px; padding:5px; }
span.frame{ display:block; overflow:hidden; }
span.frame > span{ border:1px solid #dddddd; display:block; float:left; overflow:hidden; margin:13px 0 0; padding:7px; width:auto; }
span.frame span img{ display:block; float:left; }
span.frame span span{ clear:both; color:#333333; display:block; padding:5px 0 0; }
span.align-center{ display:block; overflow:hidden; clear:both; }
span.align-center > span{ display:block; overflow:hidden; margin:13px auto 0; text-align:center; }
span.align-center span img{ margin:0 auto; text-align:center; }
span.align-right{ display:block; overflow:hidden; clear:both; }
span.align-right > span{ display:block; overflow:hidden; margin:13px 0 0; text-align:right; }
span.align-right span img{ margin:0; text-align:right; }
span.float-left{ display:block; margin-right:13px; overflow:hidden; float:left; }
span.float-left span{ margin:13px 0 0; }
span.float-right{ display:block; margin-left:13px; overflow:hidden; float:right; }
span.float-right > span{ display:block; overflow:hidden; margin:13px auto 0; text-align:right; }
code, tt{ margin:0 2px; padding:0 5px; white-space:nowrap; border:1px solid #eaeaea; background-color:#f8f8f8; border-radius:3px; }
pre code{ margin:0; padding:0; white-space:pre; border:none; background:transparent; }
.highlight pre{ background-color:#f8f8f8; border:1px solid #cccccc; font-size:13px; line-height:19px; overflow:auto; padding:6px 10px; border-radius:3px; }
pre{ background-color:#f8f8f8; border:1px solid #cccccc; font-size:13px; line-height:19px; overflow:auto; padding:6px 10px; border-radius:3px; }
pre code, pre tt{ background-color:transparent; border:none; }
@media screen and (min-width: 914px){
    body{ width:854px; margin:0 auto; }
}</style>
<style type="text/css">
</style>
</head>
<body><style>
body {font-family: Palatino}
</style>

<h2><center> Selected Problem Solutions</h2>

<p><center>from</center></p>

<h3><center>Ross, S., 1992. <i>Applied Probability Models with Optimization Applications.</i>  Dover, New York</h3>

<h3><center>Chapter 1: Introduction to Stochastic Processes</h3>

<h3><center>&copy; 2016, 2025 by</h3>

<h3><center>David Lawrence Goldsmith</h3>

<p><center>for</center></p>

<h2><center><a href="https://olydlg.github.io/selectedsolutionsdotnet/">SelectedSolutionsDotNet</a></h2>

<p><i>Note:  These solutions are provided <q>as-is,</q> for informational purposes only, with no warranty of any kind, expressed or implied, including that of correctness, adequacy, and/or suitability for any purpose, whatsoever.</i> Corrections are welcome and should be emailed to <a href="mailto:selectedsolutionsdotnet@gmail.com">selectedsolutionsdotnet@gmail.com</a>.</p>

<p>3) Given \(X, Y\) independent Poisson RV&#39;s, find the distribution of \(X + Y\).</p>

<p>Sln: We use the fact (pg. 3) that the characteristic function of a sum of independent RV&#39;s is the product of the characteristic functions of the summands. From the table on page 4, we have that \(X \sim \text{POIS} (\lambda)\) has characteristic function \(\phi_X(u) = \exp[\lambda(e^{iu}-1)]\), so for the sum of two independent Poisson RV&#39;s, we have: \[\phi_{X+Y}(u)=\phi_X(u)\phi_Y(u) = \exp[\lambda_X(e^{iu}-1)]\exp[\lambda_Y(e^{iu}-1)] = \exp[(\lambda_X + \lambda_Y)(e^{iu}-1)]\] which is recognized to be the characteristic function of a Poisson RV with parameter \(\lambda = \lambda_X + \lambda_Y\). In other words, the required distribution is \(\boxed{\text{POIS}(\lambda_X + \lambda_Y)}\).</p>

<p><br>
4) Given \(X \sim \text{POIS}(\lambda_1), Y \sim \text{POIS}(\lambda_2)\), show that \((X \mid X + Y) \sim \text{BIN}(n,p)\) for some whole number \(n\), and some real number \(p : 0 \lt p \lt 1\). </p>

<p>Pf: \(P(X \mid X + Y) = P(X=x \mid X+Y=n\in \mathbb{W}) = P(X=x, X+Y=n)~/~P(X+Y=n)\) 
\(= P(X=x, Y=n-x)~/~P(X+Y=n)\). Now, by 3), \(P(X+Y = n)= e^{-(\lambda_1 + \lambda_2)}(\lambda_1 + \lambda_2)^n/n!\), so  \(P(X=x, Y=n-x)~/~P(X+Y=n) =\) \[\frac{n!e^{(\lambda_1 + \lambda_2)}}{(\lambda_1 + \lambda_2)^n}\frac{e^{-\lambda_1}\lambda_1^x}{x!}\frac{e^{-\lambda_2}\lambda_2^{n-x}}{(n-x)!}=\left(\!
  \begin{array}{c}
    n \\
    x
  \end{array}
  \!\right)
  \left(\frac{\lambda_1}{\lambda_1 + \lambda_2}\right)^x
  \left(\frac{\lambda_2}{\lambda_1 + \lambda_2}\right)^{(n-x)}\]
\(=~_nC_xp^x(1-p)^{(n-x)}\), with \(p=\lambda_1 / (\lambda_1 + \lambda_2)\), and, given that \(\lambda_1\) and \(\lambda_2\) are both \(\gt 0, 0 \lt p \lt 1.~~~\blacksquare\)</p>

<p><br>
5) Find the distribution of \(X\), given that \(X \sim \text{POIS}\) with \(EX=\lambda \sim \text{EXP}\) with \(E\lambda = 1/\mu\).</p>

<p>Sln: The <q>trick</q> here is to recognize that the <q>distribution of \(X\)</q> being sought is the <i>marginal</i> distribution: \(P_X(x) = \lim_{\lambda \rightarrow \infty} P\{X=x,\Lambda \le \lambda\}\text{ (Expression 1)}= \lim_{\lambda \rightarrow \infty}\int_{-\infty}^{\lambda}P\{X = x \mid \Lambda \le \lambda\}dP\{\Lambda \le \lambda\}\) (Expression 2). (If you&#39;re wondering how I got from Expression 1 (1) to the integrand in Expression 2 (2) using only the material in this Chapter, I&#39;m sympathetic: the closest I can point to is the relationship, given on page 7, between a joint probability density, a corresponding conditional density, and the marginal density of the <q>conditioned-on</q> RV, \(f_{Y \mid X}(y \mid x) = f_{X,Y}(x,y)/f_X(x)\), and appeal to the pre-requisite level stated in the book&#39;s Preface, but I agree, (1) to (2) is a bit of a stretch, given only the material Ross has given us in Chapter 1.) Now, \(\lambda \gt 0\) implies that the bottom integration limit, \(-\infty\), can be replaced with \(0\), and \(\lambda \sim \text{EXP}\) with \(E\lambda = 1/\mu \Rightarrow dP\{\Lambda \le \lambda \} = \mu e^{-\mu\lambda}\) so (2) becomes:
 \[P_X (x) = \int_0^{\infty}\frac{\lambda^x e^{-\lambda} }{x!}\mu e^{-\mu\lambda} d\lambda =\frac\mu{x!}\int_0^{\infty}\lambda^x e^{-\lambda(1+\mu)}d\lambda = \frac\mu{x!}\frac{x!}{(1+\mu)^{x+1}}\] (where, via Google Search, we&#39;ve used Kirk A. Peterson&#39;s <a href="http://tyr0.chem.wsu.edu/%7Ekipeters/Chem332/resources/TableofUsefulIntegrals.pdf">online table of integrals, accessed 2015-11-14</a> for the value of the <q>improper</q> integral) \[= \frac\mu{1+\mu}\left(\frac1{1+\mu}\right)^x = p(1-p)^x \text{, where } p = \frac\mu{1+\mu} \in (0,1)~~(\text{since }\mu \gt 0)\] \(\\ \Rightarrow (1-p) \in (0,1) \Rightarrow\) \[\boxed{X \sim \text{GEOM}\left[\frac{\mu}{1+\mu}\right]}.\]  </p>

<p><br>
6) An urn has \(n\) chips [all distinguishable from one another...is what I&#39;m going to assume; for an additional exercise, assume \(n\) can be divided up, not necessarily equally, into \(m \lt n\) equivalence classes of indistinguishable chips, with every chip in precisely one class]. Chips are drawn one at a time, [recorded], and then put back in the urn. Let \(N\) denote the number of draws required UNTIL [em. added] some chip is drawn a second time. Find \(P(N)\). </p>

<p>Sln: \(P_n(N=j,~j=1,…, n) \equiv P_n(N =~\)number of draws before duplicate), so first we need to prove that \(\{1,…, n\}\) is indeed the sample space, \(S\). First, I submit as obvious that the sample space is discrete: one can only have an integer number of <q>draws</q> (including allowing for the possibility of <q>deposits</q>). Now, on the lower end, one must have at least 1 draw before a duplicate—there&#39;s no way to get a duplicate on one&#39;s 1<sup>st</sup> draw, so the lower bound for \(N\) is 1. On the top end, it is possible that one draws all \(n\) distinct chips before one&#39;s first duplicate, but if that happens, the \(n + \)1<sup>st</sup> draw is guaranteed to be a duplicate, so \(n\) is the maximum number of draws possible (before a dupe). We assume—unless the derivation of \(P_n\) indicates otherwise—that \(j =\) number of draws, can equal any integer value between its just-shown minimum of 1 and maximum of \(n\). Thus the enumeration of \(S\) as {\(1,…, n\)} has been established. (Having established the primary importance of \(n\) as defining the maximum value in \(S\), we will now drop its subscripting of \(P\) and define \(P\{N=j\} =\) our prior notion of \(P_n\{N=j\}\), i.e., the dependence  on some positive integer \(n \ge 1\) is henceforth understood.)</p>

<p>Now, for \(n\) distinguishable chips, the <q>event</q> \(N=j\) occurs as follows: 
the first \(j\) draws are all different from one another, the \(j+1\)<sup>st</sup> draw repeats one of the previous \(j\) results, and the rest of the draws—up to and including the \(n\)<sup>th</sup> —can be any of the \(n\) chips (all such sequences must be counted to get the total number of different ways \(N=j\)).  Likewise, to get said total, we need to count the different possibilities for the first \(j\) draws as if order matters (drawing a blue chip before a red chip, say, has to be counted separately from drawing a red chip before a blue).  Thus the number of different ways for the first \(j\) draws is \(_nP_j\), the number of permutations of \(n\) things taken \(j\) at a time (when order matters) \(\displaystyle= \frac{n!}{(n-j)!}\); the number of different, <q>satisfying</q> choices for the \(j+1\)<sup>st</sup> draw is \(j\) (i.e., one of the prior \(j\) choices); and the number of <q>satisfying</q> choices for the last \(n-(j+1)\) draws is \(n^{n-(j+1)}\); putting it all together, we get that the total number of different ways of satisfying \(N=j\) is \(_nP_j j n^{n-(j+1)}\). On the other hand, the total number of distinguishable sequences of \(n\) draws of \(n\) objects, with replacement and order mattering, is simply \(n^n\). Thus we finally arrive at: \[P\{N=j\} = \frac{n! j n^{n-(j+1)}}{(n-j)!n^n} = \boxed{\frac{n!}{(n-j)!}jn^{-(j+1)}}.\]</p>

<p>As a check, we confirm that our result is at least a valid probability density by evaluating \(\sum_{j=1}^{n}P\{N=j\}  = \) 
\[\sum_{j=1}^{n} \frac{n!}{(n-j)!}jn^{-(j+1)} = 
\sum_{j=1}^{n} \frac{n!}{(n-j)!}(n-(n-j))n^{-(j+1)}~^{^{(*)}}\] \[=\sum_{j=1}^{n-1}\left[ \frac{n!}{(n-j)!} n^{-j} - \frac{n!}{(n-j-1)!}n^{-(j+1)}\right] + \frac{n!}{0!}n^{-n} = \sum_{j=1}^{n-1}\left(A_j - B_j\right) + \frac{n!}{n^n},\]
where \(A_j = \displaystyle\frac{n!}{(n-j)!}n^{-j},~B_j = \frac{n!}{(n-j-1)!}n^{-(j+1)}\). We now observe that \(B_{j-1} = n!/(n-(j-1)-1)!n^{-(j-1+1)} = n!/(n-j)!n^{-j} = A_j\) and thus rewrite our last result as 
\[\sum_{j=1}^{n-1}\left(A_j - B_j\right) + \frac{n!}{n^n} = \sum_{j=1}^{n-1}\left(B_{j-1} - B_j\right) + \frac{n!}{n^n} = B_0 - B_1 + B_1 - B_2 + … + B_{n-2} - B_{n-1} + \frac{n!}{n^n}\]
\[= B_0 - B_{n-1} + \frac{n!}{n^n} = \frac{n!}{(n-1)!}n^{-1} - \frac{n!}{(n-(n-1)-1)!}n^{-(n-1+1)} + \frac{n!}{n^n} = \frac{n!}{n!} - \frac{n!}{0!}n^{-n} + \frac{n!}{n^n} = 1~~\checkmark\] </p>

<p>(* Thanks to <a href="http://qr.ae/Rg2dmZ">Ankush Jain, via Quora</a>, for pointing out that the \(j = n-(n-j)\) <q>trick</q> would work to complete this derivation.)</p>

<p><br>
9) Let \(N\) denote the number of customers arriving at a store in a given day. Suppose that the amounts spent by the customers are independent and have a [common] distribution \(F\). Find the mean and variance of the total amount of money spent in the store [per day].</p>

<p>Sln: We assume that \(N\) is distributed Poisson with parameter \(\lambda = EN\), and that \(EF = \mu\) is the expected expenditure per customer.  Then the expected income from \(n\) customers is \(n\mu\) and the expected daily income = \(\sum_{n=0}^{\infty}n\mu P(N=n) = \mu\sum_{n=0}^{\infty}ne^{-\lambda}\lambda^n/n! = \mu\sum_{n=1}^{\infty} e^{-\lambda}\lambda^n/(n-1)! = \)<br>\(\mu\sum_{n=0}^{\infty}e^{-\lambda}\lambda^{n+1}/n! = \mu\lambda\sum_{n=0}^{\infty}e^{-\lambda}\lambda^n/n! = \) \[\boxed{\mu\lambda},\] i.e., the expected number of customers per day times the expected expenditure per customer, just as intuition would suggest.</p>

<p>To compute the variance, we need to evaluate \(E(X^2) - (EX)^2\), where \(X\) represents the (random) income per day. We already know \((EX)^2 = (\mu\lambda)^2\), so we are left to evaluate \(E(X^2) = \)<br><br>\(\sum_{n=0}^{\infty}(n\mu)^2P(N=n) = \mu^2\sum_{n=0}^{\infty}n^2e^{-\lambda}\lambda^n/n! = \mu^2\left[\lambda e^{-\lambda} + \sum_{n=2}^{\infty}ne^{-\lambda}\lambda^n/(n-1)!\right] = \)<br><br>\(\mu^2\left[\lambda e^{-\lambda} + \sum_{n=0}^{\infty}(n+2)e^{-\lambda}\lambda^{n+2}/(n+1)!\right] = \mu^2\lambda\left[e^{-\lambda} + \sum_{n=0}^{\infty}((n+1)+1)e^{-\lambda}\lambda^{n+1}/(n+1)!\right] =\)<br><br>\(\mu^2\lambda\left[e^{-\lambda} + \sum_{n=0}^{\infty}(n+1)e^{-\lambda}\lambda^{n+1}/(n+1)! + \sum_{n=0}^{\infty}e^{-\lambda}\lambda^{n+1}/(n+1)!\right] = \)<br><br>\(\mu^2\lambda\left[e^{-\lambda} + \lambda\sum_{n=0}^{\infty}e^{-\lambda}\lambda^n/n! + \sum_{n=1}^{\infty}e^{-\lambda}\lambda^n/n!\right] = \mu^2\lambda\left[e^{-\lambda} + \lambda(1) + (1-e^{-\lambda})\right] = \mu^2\lambda(\lambda + 1) \therefore\) 
\[\text{Var}(X) = \mu^2\lambda^2 + \mu^2\lambda - (\mu\lambda)^2 = \boxed{\lambda\mu^2}.\]</p>

<p><br>
10) Show that any Process with independent increments is Markov.</p>

<p>Sln: We need to show that assuming independent increments is sufficient to ensure that \(P\{X \le x \mid X_1 \le x_1,  X_2 \le x_2, …, X_n \le x_n\} = P\{X \le x \mid X_n \le x_n\}~\forall t &gt; t_n &gt;t_{n-1}&gt;…&gt;t_2&gt;t_1\). By induction on \(P\{X \mid Y\} = P\{X, Y\}/P\{Y\}\) it can be established that \(P\{X \mid X_1, X_2, …, X_n\} = P\{X, X_1, X_2,…, X_n\}/\prod_{i=1}^{n}P\{X_i\}\), thus \(P\{X \le x \mid X_1 \le x_1,  X_2 \le x_2, …, X_n \le x_n\} = P\{X \le x, X_1 \le x_1,  X_2 \le x_2, …, X_n \le x_n\}/\Pi,~\text{where}~\Pi = \prod_{i=1}^{n}P\{X_i \le x_i\}\). Now the condition of independent increments is stated for us as: \(\forall~t_0 &lt; t_1 &lt;…&lt; t_n,\) the \(n\) random variables \(X_1 - X_0, X_2 - X_1, …, X_n - X_{n-1}\) are all mutually independent; since \(X \le x, Y \le y \Rightarrow X - Y \le x - y\), we have that \(P\{X \le x, X_1 \le x_1,  X_2 \le x_2, …, X_n \le x_n\}/\Pi =\) \(P\{X - X_n \le x - x_n, X_n - X_{n-1} \le x_n - x_{n-1}, …, X_2 - X_1 \le x_2 - x_1\} / \Pi = \) (because the assumption of independent increments \(\Rightarrow\) the probability of all those inequalities being true simultaneously is the product of the probabilities of each of them being true separately) \(P\{X-X_n \le x - x_n\} \cdot \prod_{i=1}^{n-1} P\{X_{i+1} - X_i \le x_{i+1} - x_i\} / \Pi =\)
<br>
\(P\{X-X_n \le x - x_n\} \cdot \prod_{i=1}^{n-1} P\{X_i \le x_i\} / \Pi =\) (because \(\Pi = P\{X_n \le x_n\} \cdot \prod_{i=1}^{n-1} P\{X_i \le x_i\}\))
<br>
\(P\{X-X_n \le x - x_n\} / P\{X_n \le x_n\}\) \(=\)
<br>
\(P\{X \le x, X_n \le x_n\} / P\{X_n \le x_n\} = \)
<br>
\(P\{X \le x \mid X_n \le x_n\}.~~~\blacksquare\)</p>

<p><br>
11) Let \(Y_{1,n}, Y_{2,n},…, Y_{n,n}\) be \(n\) independent random variables with identical [continuous] uniform distibution on \((0,t)\) [i.e., relative to the notation used in the text&#39;s Table 2, \(a = 0\) and \(b = t\)]. Let \(Z_n = \min(Y_{1,n},…, Y_{n,n})\).</p>

<p>a) Find \(P\{Z_n &gt; x\}\).</p>

<p>Sln: \(P\{\min (Y_{1,n},…, Y_{n,n}) &gt; x\} = P\{Y_{1,n} &gt; x, Y_{2,n} &gt; x,…, Y_{n,n} &gt; x\}\) and since the \(Y_{i,n}\) are all independent of one another and identically distributed, this last equals \((P\{Y_{,n} &gt; x\})^n = (1 - P\{Y_{,n} \le x\})^n =  (1 - \int_0^x\frac1t d\xi)^n = \) \[\boxed{\left(1 - \frac xt \right)^n}.\]</p>

<p>b) Let \(t\) be a function of \(n\) such that \(\lim_{n\rightarrow \infty}n/t = \lambda\). Show that \(\lim_{n \rightarrow \infty} P\{Z_n &gt; x\} = e^{-\lambda x}.\) </p>

<p>Sln: \(\lim_{n \rightarrow \infty} n/t(n) = \lambda \Rightarrow \lim_{n \rightarrow \infty} t(n) \sim n/\lambda\).  Substituting this in for \(t\) in the result for part a) and taking the limit as \(n \rightarrow \infty\) yields \(\lim_{n \rightarrow \infty} (1 - \lambda x / n)^n\), which, as a standard result from Calculus (or evaluate the limit of the logarithm of the expression using L&#39;Hopitals&#39; Rule to find that it equals \(-\lambda x\)), equals \(e^{-\lambda x}\), as claimed.</p>

<p><br>
13) Show for the Wiener process that Var\(~X(t) = \sigma^2 t\) for some \(\sigma ^2 &gt; 0.\)</p>

<p>\(\text{Var}~X(t) = E(X^2(t)) - [E(X(t))]^2\), and since \(X(t)\) is a Wiener process, \(E(X(t)) = 0~\forall t&gt;0\) so \(\text{Var}~X(t) = E(X^2(t)) = \int_{0}^{t} dt \int_{-\infty}^{\infty}x^2 \exp(-x^2/(2\sigma ^2))/\sqrt{2\pi \sigma^2} dx = t(\text{Var}(\text{Normal}(0, \sigma^2))) = \sigma^2 t.~~~\blacksquare\)</p>

<h3>Please Donate:</h3>

<table>
  <tr style="border: none; background: transparent;">
    <td style="border: none;">
      <b>Venmo: @David-Goldsmith-13</b>
    </td>
    <td style="border: none;">
      <form action="https://www.paypal.com/cgi-bin/webscr"
            method="post"><input name="cmd"
            value="_xclick" type="hidden"> <input name="business"
            value="dgoldsmith_89@alumni.brown.edu" type="hidden"> <input
            name="item_name" value="SelectedSolutions Donation"
            type="hidden"> <input name="cn" value="Special Instructions
            (optional" type="hidden"> <input
            src="https://www.paypal.com/images/x-click-but04.gif"
            name="submit" alt="Make payments with PayPal - it's fast,
            free and secure!" align="middle" border="0" type="image"></form>
    </td>
  </tr>
</table>
<script type='text/javascript' src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_HTMLorMML'></script>
<script type='text/javascript'>function reloadMathJax(){MathJax.Hub.Queue(["Typeset",MathJax.Hub]);}</script></body>
</html>